{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection and preprocessing\n",
    "\n",
    "To start, we'll import all the packages we're going to be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graeme/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "import visualisations as vis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Elections\n",
    "\n",
    "The first data processing we'll carry out is amalgamating the results of the last 4 general elections and the 2016 EU membership referendum for each constituency taken from the boundaries introduced in the 2010 general election. Most of the constituency leave vote share data comes from estimates made by Chris Hanretty. After merging, we'll end up with a single DataFrame called ge2010_2019_df. This is the primary table we'll use throughout our analysis from this point onwards. Each constituency is represented by a single row in this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ons_id</th>\n",
       "      <th>constituency_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>region_name</th>\n",
       "      <th>country_name</th>\n",
       "      <th>2019_result</th>\n",
       "      <th>2019_first_party</th>\n",
       "      <th>2019_second_party</th>\n",
       "      <th>2019_electorate</th>\n",
       "      <th>2019_valid_votes</th>\n",
       "      <th>...</th>\n",
       "      <th>2010_green</th>\n",
       "      <th>2010_snp</th>\n",
       "      <th>2010_pc</th>\n",
       "      <th>2010_dup</th>\n",
       "      <th>2010_sf</th>\n",
       "      <th>2010_sdlp</th>\n",
       "      <th>2010_uup</th>\n",
       "      <th>2010_alliance</th>\n",
       "      <th>2010_other</th>\n",
       "      <th>2010_valid_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W07000049</td>\n",
       "      <td>Aberavon</td>\n",
       "      <td>West Glamorgan</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Lab hold</td>\n",
       "      <td>Lab</td>\n",
       "      <td>Con</td>\n",
       "      <td>50750</td>\n",
       "      <td>31598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>30958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W07000058</td>\n",
       "      <td>Aberconwy</td>\n",
       "      <td>Clwyd</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Con hold</td>\n",
       "      <td>Con</td>\n",
       "      <td>Lab</td>\n",
       "      <td>44699</td>\n",
       "      <td>31865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5341.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>29966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S14000001</td>\n",
       "      <td>Aberdeen North</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SNP hold</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Con</td>\n",
       "      <td>62489</td>\n",
       "      <td>37413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>37701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S14000002</td>\n",
       "      <td>Aberdeen South</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SNP gain from Con</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Con</td>\n",
       "      <td>65719</td>\n",
       "      <td>45638</td>\n",
       "      <td>...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>5102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>43034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S14000003</td>\n",
       "      <td>Airdrie and Shotts</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>SNP hold</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Lab</td>\n",
       "      <td>64011</td>\n",
       "      <td>39772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>35849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ons_id   constituency_name     county_name region_name country_name  \\\n",
       "0  W07000049            Aberavon  West Glamorgan       Wales        Wales   \n",
       "1  W07000058           Aberconwy           Clwyd       Wales        Wales   \n",
       "2  S14000001      Aberdeen North        Scotland    Scotland     Scotland   \n",
       "3  S14000002      Aberdeen South        Scotland    Scotland     Scotland   \n",
       "4  S14000003  Airdrie and Shotts        Scotland    Scotland     Scotland   \n",
       "\n",
       "         2019_result 2019_first_party 2019_second_party  2019_electorate  \\\n",
       "0           Lab hold              Lab               Con            50750   \n",
       "1           Con hold              Con               Lab            44699   \n",
       "2           SNP hold              SNP               Con            62489   \n",
       "3  SNP gain from Con              SNP               Con            65719   \n",
       "4           SNP hold              SNP               Lab            64011   \n",
       "\n",
       "   2019_valid_votes  ...  2010_green  2010_snp  2010_pc  2010_dup  2010_sf  \\\n",
       "0             31598  ...         0.0       0.0   2198.0       0.0      0.0   \n",
       "1             31865  ...         0.0       0.0   5341.0       0.0      0.0   \n",
       "2             37413  ...         0.0    8385.0      0.0       0.0      0.0   \n",
       "3             45638  ...       413.0    5102.0      0.0       0.0      0.0   \n",
       "4             39772  ...         0.0    8441.0      0.0       0.0      0.0   \n",
       "\n",
       "   2010_sdlp  2010_uup  2010_alliance  2010_other  2010_valid_votes  \n",
       "0        0.0       0.0            0.0      2753.0             30958  \n",
       "1        0.0       0.0            0.0       137.0             29966  \n",
       "2        0.0       0.0            0.0       903.0             37701  \n",
       "3        0.0       0.0            0.0       667.0             43034  \n",
       "4        0.0       0.0            0.0       528.0             35849  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Election results\n",
    "columns = [\"ons_id\", \"constituency_name\", \"county_name\", \"region_name\", \"country_name\", \"result\", \n",
    "           \"first_party\", \"second_party\", \"electorate\", \"valid_votes\", \"invalid_votes\", \"con\", \n",
    "           \"lab\", \"ld\", \"brexit\", \"ukip\", \"green\", \"snp\", \"pc\", \"dup\", \"sf\", \"sdlp\", \"uup\", \"alliance\", \n",
    "           \"other\", \"turnout_const\", \"turnout_reg\"]\n",
    "\n",
    "ge2019_df = pd.read_csv(\"csvs/ge2019.csv\").filter(columns).add_prefix(\"2019_\")\n",
    "\n",
    "columns = [col for col in  columns if col not in [\"constituency_name\", \"county_name\", \"region_name\", \"country_name\"]]\n",
    "ge2019_df.rename({\"2019_ons_id\": \"ons_id\", \"2019_constituency_name\": \"constituency_name\", \"2019_county_name\": \"county_name\", \"2019_region_name\": \"region_name\", \"2019_country_name\": \"country_name\"}, axis=1, inplace=True)\n",
    "\n",
    "ge2017_df = pd.read_csv(\"csvs/ge2017.csv\").filter(columns).add_prefix(\"2017_\")\n",
    "ge2015_df = pd.read_csv(\"csvs/ge2015.csv\").filter(columns).add_prefix(\"2015_\")\n",
    "ge2010_df = pd.read_csv(\"csvs/ge2010.csv\").add_prefix(\"2010_\")\n",
    "ge2010_df = ge2010_df.fillna(0)\n",
    "\n",
    "ge2010_2019_df = pd.merge(ge2019_df, ge2017_df, left_on=\"ons_id\", right_on=\"2017_ons_id\")\n",
    "ge2010_2019_df = pd.merge(ge2010_2019_df, ge2015_df, left_on=\"ons_id\", right_on=\"2015_ons_id\")\n",
    "ge2010_2019_df = pd.merge(ge2010_2019_df, ge2010_df, left_on=\"ons_id\", right_on=\"2010_ons_id\")\n",
    "\n",
    "ge2010_2019_df.drop(inplace=True, axis=1, labels=[\"2017_ons_id\", \"2015_ons_id\", \"2010_ons_id\"])\n",
    "\n",
    "ge2010_2019_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2010, constituency and boundary changes for England, Scotland and Wales were implemented. The same happened for Scotland in 2005. For example, some constituencies completed disappeared, others were merged into several new constituencies and some had their boundaries slightly changed while being completely renamed. This makes analysing longer term trends harder as some constituencies have only exisited in their current makeup since 2010. Without doing anything too fancy, we're going to do our best to get as many constituencies as possible lined up with 1997 and 2019 data. In the future, I may revisit this to do something more fancy and accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_1918_2019_df = pd.read_csv(\"csvs/ge1918_2019.csv\")\n",
    "ge_1918_2019_df.rename({\"constituency\": \"constituency_name\", \"country/region\": \"region_name\"}, axis=1, inplace=True)\n",
    "ge_1918_2019_df[\"constituency_name\"] = ge_1918_2019_df[\"constituency_name\"].str.replace(\"&\", \"AND\")\n",
    "\n",
    "# TODO: could be optimised and fix SettingWithCopyWarning\n",
    "# Calculate snp and pc components\n",
    "def convert_natSW_to_snp_pc(ge_df):\n",
    "    snp = []\n",
    "    pc = []\n",
    "    for index, row in ge_df.iterrows():\n",
    "        if (row[\"region_name\"] == \"Scotland\"):\n",
    "            snp.append(row[\"natSW\"])\n",
    "            pc.append(np.nan)\n",
    "        elif (row[\"region_name\"] == \"Wales\"):\n",
    "            snp.append(np.nan)\n",
    "            pc.append(row[\"natSW\"])\n",
    "        else:\n",
    "            snp.append(np.nan)\n",
    "            pc.append(np.nan)\n",
    "    ge_df[\"snp\"] = snp\n",
    "    ge_df[\"pc\"] = pc\n",
    "    ge_df.drop(inplace=True, axis=1, labels=[\"natSW\"])\n",
    "    return ge_df\n",
    "\n",
    "ge2005_df = convert_natSW_to_snp_pc(ge_1918_2019_df[ge_1918_2019_df[\"election\"] == \"2005\"]).add_prefix(\"2005_\")\n",
    "ge2001_df = convert_natSW_to_snp_pc(ge_1918_2019_df[ge_1918_2019_df[\"election\"] == \"2001\"]).add_prefix(\"2001_\")\n",
    "ge1997_df = convert_natSW_to_snp_pc(ge_1918_2019_df[ge_1918_2019_df[\"election\"] == \"1997\"]).add_prefix(\"1997_\")\n",
    "\n",
    "# Change constituency names for 2010-2019 to be all uppercase and replace all &s with ANDs\n",
    "ge2010_2019_df[\"constituency_name\"] = ge2010_2019_df[\"constituency_name\"].str.upper()\n",
    "ge2010_2019_df[\"constituency_name\"] = ge2010_2019_df[\"constituency_name\"].str.replace(\"&\", \"AND\")\n",
    "\n",
    "ge1997_2001_df = pd.merge(ge1997_df, ge2001_df, left_on=\"1997_constituency_id\", right_on=\"2001_constituency_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2005, a number of Scottish constituencies changed but some stayed the same, or at least their name did. Below, we'll try to match the pre-2005 scottish constituencies that didn't change their name entirley with their 2005 counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by isolating the english, welsh and irish constituencies that kept the same ids as they did not change in 2005\n",
    "ge1997_2005_eng_wales_ni_df = pd.merge(\n",
    "    ge1997_2001_df[ge1997_2001_df[\"2001_region_name\"] != \"Scotland\"], \n",
    "    ge2005_df[ge2005_df[\"2005_region_name\"] != \"Scotland\"],\n",
    "    left_on=\"2001_constituency_id\",\n",
    "    right_on=\"2005_constituency_id\")\n",
    "\n",
    "# TODO: optimise below\n",
    "# We're going to attempt to match up each of the pre-2005 Scottish constituencies with their 2005 conunterparts\n",
    "ge1997_2001_scotland_df = ge1997_2001_df[ge1997_2001_df[\"2001_region_name\"] == \"Scotland\"]\n",
    "ge2005_scotland_df = ge2005_df[ge2005_df[\"2005_region_name\"] == \"Scotland\"]\n",
    "\n",
    "# We'll use fuzzywuzzy to account for ordering differences of constituency names \n",
    "def find_2001_2005_scottish_con_pairs(row):\n",
    "    con_2001 = row[\"2001_constituency_name\"]\n",
    "    cons_2005 = set(ge2005_scotland_df[\"2005_constituency_name\"].values)\n",
    "    for con_2005 in cons_2005:\n",
    "        if (fuzz.token_sort_ratio(con_2001, con_2005) == 100):\n",
    "            row[\"2001_constituency_name\"] = con_2005\n",
    "            break\n",
    "    return row\n",
    "\n",
    "ge1997_2001_scotland_df = ge1997_2001_scotland_df.apply(find_2001_2005_scottish_con_pairs, axis=1)\n",
    "\n",
    "ge1997_2005_scotland_df = pd.merge(\n",
    "    ge2005_scotland_df,\n",
    "    ge1997_2001_scotland_df,\n",
    "    left_on=\"2005_constituency_name\",\n",
    "    right_on=\"2001_constituency_name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "ge1997_2005_df = pd.concat([ge1997_2005_eng_wales_ni_df ,ge1997_2005_scotland_df])\n",
    "ge1997_2005_df.drop(inplace=True, axis=1, labels=['1997_constituency_id', '1997_constituency_name', '1997_region_name', '1997_boundary_set',\n",
    "                                                    '2001_constituency_id', '2001_constituency_name', '2001_region_name', '2001_boundary_set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll attempt to do something similar for the 2010 constituency changes in England, Wales and Northern Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge1997_2019_scotland_df = pd.merge(\n",
    "    ge1997_2005_df,\n",
    "    ge2010_2019_df,\n",
    "    left_on=\"2005_constituency_id\",\n",
    "    right_on=\"ons_id\"\n",
    ")\n",
    "\n",
    "# TODO: optimise below\n",
    "# We're going to attempt to match up each of the pre-2010 constituencies with their 2010 conunterparts\n",
    "ge1997_2005_not_scotland_df = ge1997_2005_df[ge1997_2005_df[\"2005_region_name\"] != \"Scotland\"]\n",
    "ge2010_2019_not_scotland_df = ge2010_2019_df[ge2010_2019_df[\"county_name\"] != \"Scotland\"]\n",
    "\n",
    "# We'll use fuzzywuzzy to account for ordering differences of constituency names \n",
    "def find_2005_2010_con_pairs(row):\n",
    "    con_2005 = row[\"2005_constituency_name\"]\n",
    "    cons_2010 = set(ge2010_2019_not_scotland_df[\"constituency_name\"].values)\n",
    "    for con_2010 in cons_2010:\n",
    "        if (fuzz.token_sort_ratio(con_2005, con_2010) == 100):\n",
    "            row[\"2005_constituency_name\"] = con_2010\n",
    "            break\n",
    "    return row\n",
    "\n",
    "ge1997_2005_not_scotland_df = ge1997_2005_not_scotland_df.apply(find_2005_2010_con_pairs, axis=1)\n",
    "\n",
    "ge1997_2019_not_scotland_df = pd.merge(\n",
    "    ge2010_2019_not_scotland_df,\n",
    "    ge1997_2005_not_scotland_df,\n",
    "    left_on=\"constituency_name\",\n",
    "    right_on=\"2005_constituency_name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "ge1997_2019_df = pd.concat([ge1997_2019_scotland_df ,ge1997_2019_not_scotland_df])\n",
    "ge1997_2019_df.drop(inplace=True, axis=1, labels=[\"1997_election\",\"2001_election\", \"2005_election\", \"2005_constituency_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South East                  83\n",
       "North West                  76\n",
       "London                      74\n",
       "West Midlands               59\n",
       "Scotland                    59\n",
       "east                        56\n",
       "Yorkshire and the Humber    56\n",
       "South West                  51\n",
       "East Midlands               44\n",
       "Wales                       40\n",
       "North East                  30\n",
       "Northern Ireland            18\n",
       "Name: 2005_region_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ge1997_2001_df.loc[ge1997_2001_df[\"1997_region_name\"] == \"Eastern\", [\"1997_region_name\"]] = \"east\"\n",
    "ge1997_2001_df.loc[ge1997_2001_df[\"2001_region_name\"] == \"Eastern\", [\"2001_region_name\"]] = \"east\"\n",
    "ge2005_df.loc[ge2005_df[\"2005_region_name\"] == \"Eastern\", \"2005_region_name\"] = \"east\"\n",
    "ge2005_df[\"2005_region_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016 EU membership referendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_ref_results_df = pd.read_csv(\"csvs/euref.csv\").filter([\"ons_id\", \"leave_share\"])\n",
    "constits_df = pd.merge(ge1997_2019_df, eu_ref_results_df, on=\"ons_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## British Election Study survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graeme/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (427,428,430) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "bes_w6_df = pd.read_csv(\"csvs/bes_datasets/BES_W6.csv\")\n",
    "bes_w6_df.rename({\"generalElectionVote\": \"general_election_vote\"}, axis=1, inplace=True)\n",
    "# wt\n",
    "bes_w6_df.loc[bes_w6_df[\"wt\"] == \" \", \"wt\"] = 0\n",
    "bes_w6_df[\"wt\"] = pd.to_numeric(bes_w6_df[\"wt\"])\n",
    "# p_past_vote_2010\n",
    "bes_w6_df.loc[bes_w6_df[\"p_past_vote_2010\"] == \" \", \"p_past_vote_2010\"] = \"Didn't vote\"\n",
    "# general_election_vote\n",
    "bes_w6_df.loc[bes_w6_df[\"general_election_vote\"] == \" \", \"general_election_vote\"] = \"Didn't vote\"\n",
    "# country\n",
    "bes_w6_df[\"country\"] = bes_w6_df[\"country\"].map({\n",
    "    \"1\": \"England\",\n",
    "    1: \"England\",\n",
    "    \"2\": \"Scotland\",\n",
    "    2: \"Scotland\",\n",
    "    \"3\": \"Wales\",\n",
    "    3: \"Wales\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graeme/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (17,18,19,20,22,23,25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'constituency_median_house_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'constituency_median_house_price'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5e4fe2ce31bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconstits_house_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ons_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2019_constituency_median_house_price\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2019_region_median_house_price\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DateOfDataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconstits_house_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DateOfDataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"2015-06-30\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constituency_median_house_price\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constituency_median_house_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"region_median_house_price\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"region_median_house_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coerce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconstits_house_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constituency_median_house_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'constituency_median_house_price'"
     ]
    }
   ],
   "source": [
    "# Doesn't work properly\n",
    "constits_house_prices = pd.read_csv(\"csvs/constituency_data/house_prices.csv\")\n",
    "constits_house_prices = constits_house_prices.rename({\"ONSConstID\": \"ons_id\", \"HouseConstMedianPrice\": \"constituency_median_house_price\", \"HouseRegionMedianPrice\": \"region_median_house_price\"}, axis=1)\n",
    "constits_house_prices = constits_house_prices.filter([\"ons_id\", \"constituency_median_house_price\", \"region_median_house_price\", \"DateOfDataset\"])\n",
    "constits_house_prices = constits_house_prices[constits_house_prices[\"DateOfDataset\"] == \"2015-06-30\"]\n",
    "constits_house_prices[\"constituency_median_house_price\"] = pd.to_numeric(constits_house_prices[\"constituency_median_house_price\"], errors=\"coerce\")\n",
    "constits_house_prices[\"region_median_house_price\"] = pd.to_numeric(constits_house_prices[\"region_median_house_price\"], errors=\"coerce\")\n",
    "constits_house_prices[\"constituency_median_house_price\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constits_df = pd.merge(constits_df, constits_house_prices[constits_house_prices[\"DateOfDataset\"] == \"2015-06-30\"], on=\"ons_id\")\n",
    "constits_df.drop(inplace=True, axis=1, labels=[\"DateOfDataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(25, 20))\n",
    "vis.create_continous_constit_map(constits_df, \"constituency_median_house_price\", fig=fig, ax=axes[0][0], title=\"level4+\", colour_map=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Educational attainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constits_education = pd.read_csv(\"csvs/constituency_data/education_levels.csv\")\n",
    "constits_df = pd.merge(constits_df, constits_education, on=\"ons_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(25, 20))\n",
    "vis.create_continous_constit_map(constits_df, \"level_4_plus\", fig=fig, ax=axes[0][0], title=\"level4+\", colour_map=\"Blues\")\n",
    "vis.create_continous_constit_map(constits_df, \"level_3_highest\", fig=fig, ax=axes[0][1], title=\"level3\", colour_map=\"Blues\")\n",
    "vis.create_continous_constit_map(constits_df, \"level_2_highest\", fig=fig, ax=axes[0][2], title=\"level2\", colour_map=\"Blues\")\n",
    "vis.create_continous_constit_map(constits_df, \"level_1_highest\", fig=fig, ax=axes[1][0], title=\"level1\", colour_map=\"Blues\")\n",
    "vis.create_continous_constit_map(constits_df, \"no_qualifications_highest\", fig=fig, ax=axes[1][1], title=\"no qual\", colour_map=\"Blues\")\n",
    "axes[1][2].axis(\"off\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish, we'll write our final datasets to csvs ready for exploration and analysis. We're also going to convert some columns to lower case to make dealing with them in the future easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cols_to_lowercase(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.object and \"id\" not in col:\n",
    "            df[col] = df[col].str.lower()\n",
    "    return df\n",
    "\n",
    "ge1997_2001_df = convert_cols_to_lowercase(ge1997_2001_df)\n",
    "ge2005_df = convert_cols_to_lowercase(ge2005_df)\n",
    "constits_df = convert_cols_to_lowercase(constits_df)\n",
    "\n",
    "ge1997_2001_df.to_csv(\"csvs/final_datasets/ge1997_2001.csv\", index=False)\n",
    "ge2005_df.to_csv(\"csvs/final_datasets/ge2005.csv\", index=False)\n",
    "constits_df.to_csv(\"csvs/final_datasets/constits.csv\", index=False)\n",
    "bes_w6_df.to_csv(\"csvs/final_datasets/bes_w6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
